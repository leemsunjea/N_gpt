#!/usr/bin/env python3
"""
ì‚¬ìš©ì ë°ì´í„° ì •ë¦¬ ìœ í‹¸ë¦¬í‹°
- ë¹„í™œì„± ì‚¬ìš©ìì˜ FAISS ì¸ë±ìŠ¤ íŒŒì¼ ì‚­ì œ
- ì˜¤ë˜ëœ ì„¸ì…˜ ë°ì´í„° ì •ë¦¬
- ì‚¬ìš©ìë³„ ë°ì´í„° í†µê³„ ì¡°íšŒ
"""

import asyncio
import os
import glob
import json
from datetime import datetime, timedelta
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, delete, func, text
from database import get_db_session, Document, DocumentChunk
from user_session import UserSessionManager

class UserDataCleaner:
    def __init__(self):
        self.faiss_index_dir = "faiss_indexes"
    
    async def get_all_user_stats(self):
        """ëª¨ë“  ì‚¬ìš©ìì˜ í†µê³„ ì¡°íšŒ"""
        async with get_db_session() as session:
            # ì‚¬ìš©ìë³„ ë¬¸ì„œ ë° ì²­í¬ ìˆ˜ ì¡°íšŒ
            result = await session.execute(text("""
                SELECT 
                    d.user_id,
                    COUNT(DISTINCT d.id) as document_count,
                    COUNT(dc.id) as chunk_count,
                    MAX(d.created_at) as last_document_upload
                FROM document d 
                LEFT JOIN documentchunk dc ON d.id = dc.document_id 
                WHERE d.user_id IS NOT NULL
                GROUP BY d.user_id
                ORDER BY last_document_upload DESC
            """))
            
            users_data = []
            for row in result:
                user_data = {
                    "user_id": row.user_id,
                    "document_count": row.document_count,
                    "chunk_count": row.chunk_count,
                    "last_document_upload": row.last_document_upload.isoformat() if row.last_document_upload else None,
                    "has_faiss_index": self.check_faiss_index_exists(row.user_id)
                }
                users_data.append(user_data)
            
            print(f"ğŸ“Š ì´ {len(users_data)}ëª…ì˜ ì‚¬ìš©ì ë°œê²¬")
            return users_data
    
    def check_faiss_index_exists(self, user_id: str) -> bool:
        """ì‚¬ìš©ìì˜ FAISS ì¸ë±ìŠ¤ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
        if not os.path.exists(self.faiss_index_dir):
            return False
        
        pattern = os.path.join(self.faiss_index_dir, f"{user_id}_*.index")
        return len(glob.glob(pattern)) > 0
    
    def get_faiss_index_files(self, user_id: str) -> list:
        """ì‚¬ìš©ìì˜ FAISS ì¸ë±ìŠ¤ íŒŒì¼ ëª©ë¡ ë°˜í™˜"""
        if not os.path.exists(self.faiss_index_dir):
            return []
        
        pattern = os.path.join(self.faiss_index_dir, f"{user_id}_*")
        return glob.glob(pattern)
    
    async def cleanup_inactive_users(self, days_threshold: int = 30) -> dict:
        """ë¹„í™œì„± ì‚¬ìš©ì ë°ì´í„° ì •ë¦¬"""
        cutoff_date = datetime.now() - timedelta(days=days_threshold)
        
        print(f"ğŸ§¹ {days_threshold}ì¼ ì´ìƒ ë¹„í™œì„± ì‚¬ìš©ì ë°ì´í„° ì •ë¦¬ ì‹œì‘")
        print(f"ê¸°ì¤€ ë‚ ì§œ: {cutoff_date.strftime('%Y-%m-%d %H:%M:%S')}")
        
        stats = {
            "inactive_users": 0,
            "deleted_documents": 0,
            "deleted_chunks": 0,
            "deleted_faiss_files": 0,
            "errors": []
        }
        
        try:
            # ë¹„í™œì„± ì‚¬ìš©ì ì°¾ê¸°
            async with get_db_session() as session:
                result = await session.execute(text("""
                    SELECT user_id, COUNT(*) as doc_count, MAX(created_at) as last_activity
                    FROM document 
                    WHERE user_id IS NOT NULL 
                    AND created_at < :cutoff_date
                    GROUP BY user_id
                """), {"cutoff_date": cutoff_date})
                
                inactive_users = result.fetchall()
                
                for user_data in inactive_users:
                    user_id = user_data.user_id
                    doc_count = user_data.doc_count
                    last_activity = user_data.last_activity
                    
                    print(f"ğŸ—‘ï¸  ì‚¬ìš©ì {user_id} ì •ë¦¬ ì¤‘... (ë¬¸ì„œ {doc_count}ê°œ, ë§ˆì§€ë§‰ í™œë™: {last_activity})")
                    
                    try:
                        # 1. DocumentChunk ì‚­ì œ
                        chunk_result = await session.execute(
                            delete(DocumentChunk).where(DocumentChunk.user_id == user_id)
                        )
                        stats["deleted_chunks"] += chunk_result.rowcount
                        
                        # 2. Document ì‚­ì œ
                        doc_result = await session.execute(
                            delete(Document).where(Document.user_id == user_id)
                        )
                        stats["deleted_documents"] += doc_result.rowcount
                        
                        # 3. FAISS ì¸ë±ìŠ¤ íŒŒì¼ ì‚­ì œ
                        faiss_files = self.get_faiss_index_files(user_id)
                        for file_path in faiss_files:
                            try:
                                os.remove(file_path)
                                stats["deleted_faiss_files"] += 1
                                print(f"  âœ… FAISS íŒŒì¼ ì‚­ì œ: {file_path}")
                            except Exception as e:
                                error_msg = f"FAISS íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨ ({file_path}): {e}"
                                print(f"  âŒ {error_msg}")
                                stats["errors"].append(error_msg)
                        
                        stats["inactive_users"] += 1
                        print(f"  âœ… ì‚¬ìš©ì {user_id} ë°ì´í„° ì •ë¦¬ ì™„ë£Œ")
                        
                    except Exception as e:
                        error_msg = f"ì‚¬ìš©ì {user_id} ë°ì´í„° ì •ë¦¬ ì‹¤íŒ¨: {e}"
                        print(f"  âŒ {error_msg}")
                        stats["errors"].append(error_msg)
                
                await session.commit()
        
        except Exception as e:
            error_msg = f"ë°ì´í„° ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"
            print(f"âŒ {error_msg}")
            stats["errors"].append(error_msg)
        
        print(f"ğŸ‰ ë°ì´í„° ì •ë¦¬ ì™„ë£Œ: {stats}")
        return stats
    
    async def cleanup_orphaned_faiss_files(self) -> dict:
        """ê³ ì•„ FAISS íŒŒì¼ ì •ë¦¬ (DBì— ì‚¬ìš©ì ë°ì´í„°ëŠ” ì—†ì§€ë§Œ FAISS íŒŒì¼ë§Œ ë‚¨ì€ ê²½ìš°)"""
        if not os.path.exists(self.faiss_index_dir):
            return {"deleted_files": 0, "errors": []}
        
        print("ğŸ§¹ ê³ ì•„ FAISS íŒŒì¼ ì •ë¦¬ ì‹œì‘")
        
        stats = {"deleted_files": 0, "errors": []}
        
        try:
            # DBì—ì„œ í™œì„± ì‚¬ìš©ì ID ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            async with get_db_session() as session:
                result = await session.execute(
                    select(Document.user_id).distinct().where(Document.user_id.isnot(None))
                )
                active_user_ids = {row.user_id for row in result}
                print(f"ğŸ“Š í™œì„± ì‚¬ìš©ì {len(active_user_ids)}ëª… ë°œê²¬")
            
            # FAISS ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  íŒŒì¼ í™•ì¸
            all_faiss_files = glob.glob(os.path.join(self.faiss_index_dir, "*"))
            
            for file_path in all_faiss_files:
                filename = os.path.basename(file_path)
                
                # íŒŒì¼ëª…ì—ì„œ user_id ì¶”ì¶œ (user_id_*.index ë˜ëŠ” user_id_*.pkl í˜•íƒœ)
                user_id = None
                for active_id in active_user_ids:
                    if filename.startswith(f"{active_id}_"):
                        user_id = active_id
                        break
                
                # í™œì„± ì‚¬ìš©ìì™€ ì—°ê²°ë˜ì§€ ì•Šì€ íŒŒì¼ì´ë©´ ì‚­ì œ
                if user_id is None:
                    try:
                        os.remove(file_path)
                        stats["deleted_files"] += 1
                        print(f"  ğŸ—‘ï¸  ê³ ì•„ íŒŒì¼ ì‚­ì œ: {filename}")
                    except Exception as e:
                        error_msg = f"ê³ ì•„ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨ ({filename}): {e}"
                        print(f"  âŒ {error_msg}")
                        stats["errors"].append(error_msg)
        
        except Exception as e:
            error_msg = f"ê³ ì•„ íŒŒì¼ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"
            print(f"âŒ {error_msg}")
            stats["errors"].append(error_msg)
        
        print(f"ğŸ‰ ê³ ì•„ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ: {stats}")
        return stats

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    cleaner = UserDataCleaner()
    
    print("=" * 50)
    print("ğŸ› ï¸  N_GPT ì‚¬ìš©ì ë°ì´í„° ì •ë¦¬ ë„êµ¬")
    print("=" * 50)
    
    while True:
        print("\nì„ íƒí•˜ì„¸ìš”:")
        print("1. ëª¨ë“  ì‚¬ìš©ì í†µê³„ ì¡°íšŒ")
        print("2. ë¹„í™œì„± ì‚¬ìš©ì ë°ì´í„° ì •ë¦¬ (30ì¼ ê¸°ì¤€)")
        print("3. ë¹„í™œì„± ì‚¬ìš©ì ë°ì´í„° ì •ë¦¬ (ì‚¬ìš©ì ì •ì˜ ê¸°ê°„)")
        print("4. ê³ ì•„ FAISS íŒŒì¼ ì •ë¦¬")
        print("5. ì¢…ë£Œ")
        
        choice = input("\në²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
        
        if choice == "1":
            print("\nğŸ“Š ì‚¬ìš©ì í†µê³„ ì¡°íšŒ ì¤‘...")
            users_stats = await cleaner.get_all_user_stats()
            
            if users_stats:
                print(f"\n{'ì‚¬ìš©ì ID':<40} {'ë¬¸ì„œ':<8} {'ì²­í¬':<8} {'FAISS':<8} {'ë§ˆì§€ë§‰ ì—…ë¡œë“œ':<20}")
                print("-" * 90)
                for user in users_stats:
                    faiss_status = "âœ…" if user["has_faiss_index"] else "âŒ"
                    last_upload = user["last_document_upload"][:19] if user["last_document_upload"] else "ì—†ìŒ"
                    print(f"{user['user_id']:<40} {user['document_count']:<8} {user['chunk_count']:<8} {faiss_status:<8} {last_upload:<20}")
            else:
                print("ì‚¬ìš©ìê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        elif choice == "2":
            print("\nğŸ§¹ ë¹„í™œì„± ì‚¬ìš©ì ë°ì´í„° ì •ë¦¬ (30ì¼ ê¸°ì¤€)...")
            confirm = input("ì •ë§ë¡œ 30ì¼ ì´ìƒ ë¹„í™œì„± ì‚¬ìš©ì ë°ì´í„°ë¥¼ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")
            if confirm.lower() == 'y':
                stats = await cleaner.cleanup_inactive_users(30)
                print(f"\nì •ë¦¬ ì™„ë£Œ: {json.dumps(stats, indent=2, ensure_ascii=False)}")
            else:
                print("ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        elif choice == "3":
            try:
                days = int(input("ë¹„í™œì„± ê¸°ì¤€ ì¼ìˆ˜ë¥¼ ì…ë ¥í•˜ì„¸ìš”: "))
                if days <= 0:
                    print("âŒ ì–‘ìˆ˜ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                    continue
                
                print(f"\nğŸ§¹ ë¹„í™œì„± ì‚¬ìš©ì ë°ì´í„° ì •ë¦¬ ({days}ì¼ ê¸°ì¤€)...")
                confirm = input(f"ì •ë§ë¡œ {days}ì¼ ì´ìƒ ë¹„í™œì„± ì‚¬ìš©ì ë°ì´í„°ë¥¼ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")
                if confirm.lower() == 'y':
                    stats = await cleaner.cleanup_inactive_users(days)
                    print(f"\nì •ë¦¬ ì™„ë£Œ: {json.dumps(stats, indent=2, ensure_ascii=False)}")
                else:
                    print("ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            except ValueError:
                print("âŒ ì˜¬ë°”ë¥¸ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        elif choice == "4":
            print("\nğŸ§¹ ê³ ì•„ FAISS íŒŒì¼ ì •ë¦¬...")
            confirm = input("ì •ë§ë¡œ ê³ ì•„ FAISS íŒŒì¼ì„ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")
            if confirm.lower() == 'y':
                stats = await cleaner.cleanup_orphaned_faiss_files()
                print(f"\nì •ë¦¬ ì™„ë£Œ: {json.dumps(stats, indent=2, ensure_ascii=False)}")
            else:
                print("ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        elif choice == "5":
            print("ğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        
        else:
            print("âŒ ì˜¬ë°”ë¥¸ ë²ˆí˜¸ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ì‚¬ìš©ìì— ì˜í•´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
